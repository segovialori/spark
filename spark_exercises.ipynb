{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within your codeup-data-science directory, create a new repo named spark-exercises. This will be where you do your work for this module. Create a repository on GitHub with the same name, and link your local repository to GitHub.\n",
    "\n",
    "Save this work in your spark-exercises repo. Then add, commit, and push your changes.\n",
    "\n",
    "Create a jupyter notebook or python script named spark101 for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#create the spark session\n",
    "import pyspark\n",
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import month, year, quarter\n",
    "from pyspark.sql.functions import col, expr\n",
    "from pyspark.sql.functions import asc, desc\n",
    "from pyspark.sql.functions import lit\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages.\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    pd.DataFrame({'language': ['python', 'java', 'r', 'c']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|    java|\n",
      "|       r|\n",
      "|       c|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark does not have a .shape function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 rows 1 columns\n"
     ]
    }
   ],
   "source": [
    "print(df.count(), \"rows\", len(df.columns), \"columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|    java|\n",
      "|       r|\n",
      "|       c|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the mpg dataset as a spark dataframe.\n",
    "- Create 1 column of output that contains a message like the one below (for each vehicle):\n",
    "The 1999 audi a4 has a 4 cylinder engine.\n",
    "- Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 1 column of output that contains a message like the one below (for each vehicle): \n",
    "- The 1999 audi a4 has a 4 cylinder engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             message|\n",
      "+--------------------+\n",
      "|The 1999 audi has...|\n",
      "|The 1999 audi has...|\n",
      "|The 2008 audi has...|\n",
      "|The 2008 audi has...|\n",
      "|The 1999 audi has...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(concat(lit('The '), mpg.year, lit(' '), mpg.manufacturer, lit(' has a '), mpg.cyl, lit(' cylinder engine')).alias('message')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|     trans| trans|\n",
      "+----------+------+\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|manual(m6)|manual|\n",
      "|  auto(av)|  auto|\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|  auto(av)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m6)|manual|\n",
      "|  auto(s6)|  auto|\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|  auto(s6)|  auto|\n",
      "|manual(m6)|manual|\n",
      "|  auto(l5)|  auto|\n",
      "|  auto(s6)|  auto|\n",
      "|  auto(s6)|  auto|\n",
      "|  auto(l4)|  auto|\n",
      "|  auto(l4)|  auto|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.trans,\n",
    "          when((mpg.trans.contains('auto')), 'auto')\n",
    "          .otherwise('manual')\n",
    "          .alias('trans')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "- What percentage of observations are smokers?\n",
    "- Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "pandas_dataframe = data(\"tips\")\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.114754098360656"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(df.smoker == 'Yes').count() / df.count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = (col('tip') / col('total_bill'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('*', col.alias('tip_pct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|\n",
      "+----------+----+------+------+----+------+----+\n",
      "|      3.07| 1.0|Female|   Yes| Sat|Dinner|   1|\n",
      "|     26.86|3.14|Female|   Yes| Sat|Dinner|   2|\n",
      "|     25.28| 5.0|Female|   Yes| Sat|Dinner|   2|\n",
      "|      5.75| 1.0|Female|   Yes| Fri|Dinner|   2|\n",
      "|     16.32| 4.3|Female|   Yes| Fri|Dinner|   2|\n",
      "|     11.35| 2.5|Female|   Yes| Fri|Dinner|   2|\n",
      "|     15.38| 3.0|Female|   Yes| Fri|Dinner|   2|\n",
      "|      44.3| 2.5|Female|   Yes| Sat|Dinner|   3|\n",
      "|     22.42|3.48|Female|   Yes| Sat|Dinner|   2|\n",
      "|     14.31| 4.0|Female|   Yes| Sat|Dinner|   2|\n",
      "|     17.51| 3.0|Female|   Yes| Sun|Dinner|   2|\n",
      "|     10.59|1.61|Female|   Yes| Sat|Dinner|   2|\n",
      "|     10.63| 2.0|Female|   Yes| Sat|Dinner|   2|\n",
      "|       9.6| 4.0|Female|   Yes| Sun|Dinner|   2|\n",
      "|      20.9| 3.5|Female|   Yes| Sun|Dinner|   3|\n",
      "|     18.15| 3.5|Female|   Yes| Sun|Dinner|   3|\n",
      "|     19.81|4.19|Female|   Yes|Thur| Lunch|   2|\n",
      "|     43.11| 5.0|Female|   Yes|Thur| Lunch|   4|\n",
      "|      13.0| 2.0|Female|   Yes|Thur| Lunch|   2|\n",
      "|     12.74|2.01|Female|   Yes|Thur| Lunch|   2|\n",
      "+----------+----+------+------+----+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#female smoker\n",
    "df.where(df.sex == 'Female').where(df.smoker == 'Yes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+----+------+----+\n",
      "|total_bill| tip|   sex|smoker| day|  time|size|\n",
      "+----------+----+------+------+----+------+----+\n",
      "|     16.99|1.01|Female|    No| Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No| Sun|Dinner|   4|\n",
      "|     35.26| 5.0|Female|    No| Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No| Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No| Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No| Sun|Dinner|   3|\n",
      "|     20.29|2.75|Female|    No| Sat|Dinner|   2|\n",
      "|     15.77|2.23|Female|    No| Sat|Dinner|   2|\n",
      "|     19.65| 3.0|Female|    No| Sat|Dinner|   2|\n",
      "|     15.06| 3.0|Female|    No| Sat|Dinner|   2|\n",
      "|     20.69|2.45|Female|    No| Sat|Dinner|   4|\n",
      "|     16.93|3.07|Female|    No| Sat|Dinner|   3|\n",
      "|     10.29| 2.6|Female|    No| Sun|Dinner|   2|\n",
      "|     34.81| 5.2|Female|    No| Sun|Dinner|   4|\n",
      "|     26.41| 1.5|Female|    No| Sat|Dinner|   2|\n",
      "|     16.45|2.47|Female|    No| Sat|Dinner|   2|\n",
      "|     17.07| 3.0|Female|    No| Sat|Dinner|   3|\n",
      "|     14.73| 2.2|Female|    No| Sat|Dinner|   2|\n",
      "|     10.07|1.83|Female|    No|Thur| Lunch|   1|\n",
      "|     34.83|5.17|Female|    No|Thur| Lunch|   4|\n",
      "+----------+----+------+------+----+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#female non-smoker\n",
    "df.where(df.sex == 'Female').where(df.smoker == 'No').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+------+----+------+----+\n",
      "|total_bill| tip| sex|smoker| day|  time|size|\n",
      "+----------+----+----+------+----+------+----+\n",
      "|     38.01| 3.0|Male|   Yes| Sat|Dinner|   4|\n",
      "|     11.24|1.76|Male|   Yes| Sat|Dinner|   2|\n",
      "|     20.29|3.21|Male|   Yes| Sat|Dinner|   2|\n",
      "|     13.81| 2.0|Male|   Yes| Sat|Dinner|   2|\n",
      "|     11.02|1.98|Male|   Yes| Sat|Dinner|   2|\n",
      "|     18.29|3.76|Male|   Yes| Sat|Dinner|   4|\n",
      "|     15.01|2.09|Male|   Yes| Sat|Dinner|   2|\n",
      "|     17.92|3.08|Male|   Yes| Sat|Dinner|   2|\n",
      "|     19.44| 3.0|Male|   Yes|Thur| Lunch|   2|\n",
      "|     32.68| 5.0|Male|   Yes|Thur| Lunch|   2|\n",
      "|     28.97| 3.0|Male|   Yes| Fri|Dinner|   2|\n",
      "|     40.17|4.73|Male|   Yes| Fri|Dinner|   4|\n",
      "|     27.28| 4.0|Male|   Yes| Fri|Dinner|   2|\n",
      "|     12.03| 1.5|Male|   Yes| Fri|Dinner|   2|\n",
      "|     21.01| 3.0|Male|   Yes| Fri|Dinner|   2|\n",
      "|     15.36|1.64|Male|   Yes| Sat|Dinner|   2|\n",
      "|     20.49|4.06|Male|   Yes| Sat|Dinner|   2|\n",
      "|     25.21|4.29|Male|   Yes| Sat|Dinner|   2|\n",
      "|      16.0| 2.0|Male|   Yes|Thur| Lunch|   2|\n",
      "|     50.81|10.0|Male|   Yes| Sat|Dinner|   3|\n",
      "+----------+----+----+------+----+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#male smoker\n",
    "df.where(df.sex == 'Male').where(df.smoker == 'Yes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+------+---+------+----+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|\n",
      "+----------+----+----+------+---+------+----+\n",
      "|     10.34|1.66|Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|Male|    No|Sun|Dinner|   2|\n",
      "|     25.29|4.71|Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|Male|    No|Sun|Dinner|   2|\n",
      "|     15.42|1.57|Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|Male|    No|Sun|Dinner|   4|\n",
      "|     21.58|3.92|Male|    No|Sun|Dinner|   2|\n",
      "|     16.29|3.71|Male|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|Male|    No|Sat|Dinner|   3|\n",
      "|     17.92|4.08|Male|    No|Sat|Dinner|   2|\n",
      "|     39.42|7.58|Male|    No|Sat|Dinner|   4|\n",
      "|     19.82|3.18|Male|    No|Sat|Dinner|   2|\n",
      "|     17.81|2.34|Male|    No|Sat|Dinner|   4|\n",
      "|     13.37| 2.0|Male|    No|Sat|Dinner|   2|\n",
      "|     12.69| 2.0|Male|    No|Sat|Dinner|   2|\n",
      "+----------+----+----+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#male non-smoker\n",
    "df.where(df.sex == 'Male').where(df.smoker == 'No').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.rollup('sex','smoker').agg(avg(df.tip_pct)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to farenheight.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "df = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "df = spark.createDataFrame(df)\n",
    "df.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the temperatures to farenheight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* (9/5) + 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|month|    total_rainfall|\n",
      "+-----+------------------+\n",
      "|   11|             642.5|\n",
      "|   12| 622.7000000000002|\n",
      "|    3|             606.2|\n",
      "|   10|             503.4|\n",
      "|    1|465.99999999999994|\n",
      "|    2|             422.0|\n",
      "|    4|             375.4|\n",
      "|    9|235.49999999999997|\n",
      "|    5|             207.5|\n",
      "|    8|             163.7|\n",
      "|    6|             132.9|\n",
      "|    7|              48.2|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('month', month('date')).groupBy('month').agg(sum('precipitation').alias('total_rainfall')).sort(desc('total_rainfall')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|        total_wind|\n",
      "+----+------------------+\n",
      "|2012|            1244.7|\n",
      "|2014|1236.5000000000007|\n",
      "|2015|1153.3000000000002|\n",
      "|2013|1100.8000000000006|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('year', year('date')).groupBy('year').agg(sum('wind').alias('total_wind')).sort(desc('total_wind')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"month\", month(\"date\")).filter(col(\"month\") == 1).groupBy(\"weather\").count().sort(col(\"count\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "| average_high_temp| average_low_temp|\n",
      "+------------------+-----------------+\n",
      "|26.828846153846158|14.18269230769231|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(col(\"weather\") == lit(\"sun\"))\n",
    "    .agg(\n",
    "        avg(\"temp_max\").alias(\"average_high_temp\"),\n",
    "        avg(\"temp_min\").alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          avg(rain)|\n",
      "+-------------------+\n",
      "|0.18478260869565216|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(year(\"date\") == 2015).filter(quarter(\"date\") == 3).select(when(col(\"precipitation\") > 0, 1).otherwise(0).alias(\"rain\")).agg(mean(\"rain\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
